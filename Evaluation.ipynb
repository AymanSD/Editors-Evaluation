{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "282a9787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "import pyodbc\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd582e8a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "083db480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel(filename):\n",
    "    wb = openpyxl.load_workbook(filename, read_only=True)\n",
    "    ws = wb['Sheet1']\n",
    "    header_row_idx = None\n",
    "    for i, row in enumerate(ws.iter_rows(max_col=2, max_row=10, values_only=True)):\n",
    "        if row and 'Case Number' in row:\n",
    "            header_row_idx = i\n",
    "            break\n",
    "    wb.close()\n",
    "    if header_row_idx is not None:\n",
    "        df = pd.read_excel(filename, sheet_name='Sheet1', skiprows=header_row_idx)\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(f\"Header row with 'Case Number' not found in: {filename}\")\n",
    "    \n",
    "def convert_to_date(df):\n",
    "    dtimeFields = ['Case Date', 'Case Submission Date','Latest Action Date','Transferred to Geospatial','GEO Completion','GEO S Completion','Transferred to Ops', 'Attachment Added Date', \"ListDate\"]\n",
    "    for field in dtimeFields:\n",
    "        if field in df.columns:\n",
    "            df[field] = pd.to_datetime(df[field]).dt.date\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f99d0",
   "metadata": {},
   "source": [
    "### DB Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26b43a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config at the top of the file\n",
    "AppDB_CONFIG = {\n",
    "    \"server\": '0003-MAAL-01\\\\LASSQLSERVER',\n",
    "    \"database\": 'LASCaseWorkerApp',\n",
    "    \"username\": 'LASCaseWorker',\n",
    "    \"password\": 'LASCaseWorker'\n",
    "}\n",
    "\n",
    "# Utility function to create a connection\n",
    "def get_connection_Sql():\n",
    "    return pyodbc.connect(\n",
    "        f\"DRIVER={{SQL Server}};\"\n",
    "        f\"SERVER={AppDB_CONFIG['server']};\"\n",
    "        f\"DATABASE={AppDB_CONFIG['database']};\"\n",
    "        f\"UID={AppDB_CONFIG['username']};\"\n",
    "        f\"PWD={AppDB_CONFIG['password']};\"\n",
    "    )\n",
    "\n",
    "## Dashboard DB SQL\n",
    "DashDB_CONFIG = {\n",
    "    \"server\": '0003-MAAL-01\\\\LASSQLSERVER',\n",
    "    \"database\": 'GRSDASHBOARD',\n",
    "    \"username\": 'lasapp',\n",
    "    \"password\": 'lasapp@LAS123'\n",
    "}\n",
    "\n",
    "# Build ODBC connection string from existing DB_CONFIG\n",
    "odbc_params = (\n",
    "    \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "    f\"SERVER={DashDB_CONFIG['server']};\"\n",
    "    f\"DATABASE={DashDB_CONFIG['database']};\"\n",
    "    f\"UID={DashDB_CONFIG['username']};\"\n",
    "    f\"PWD={DashDB_CONFIG['password']};\"\n",
    ")\n",
    "\n",
    "DashPost = {\n",
    "    \"server\":\"10.150.40.74\",\n",
    "    \"port\": '5432',\n",
    "    \"database\": \"GSA\",\n",
    "    \"username\": \"app_user\",\n",
    "    \"password\": \"app1234\"\n",
    "}\n",
    "## Dashboard DB PostgreSQL\n",
    "connection_str_post = f\"postgresql://{DashPost['username']}:{DashPost['password']}@{DashPost['server']}:{DashPost['port']}/{DashPost['database']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd32c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "odbc_connect_str = urllib.parse.quote_plus(odbc_params)\n",
    "# Create SQLAlchemy engine for SQL Server via pyodbc\n",
    "engine_sqlserver = create_engine(f\"mssql+pyodbc:///?odbc_connect={odbc_connect_str}\", fast_executemany=True)\n",
    "engine_postgres = create_engine(connection_str_post)\n",
    "tables = ['ApprovedCases', 'CR_Current', 'CR_Data', 'ClassificationData', 'CurrentCases', 'EditorsList', 'GeoData', 'GeoSCompletionData', 'HistoricalData', 'MG_Current', 'MG_Data', 'OpsData', 'RejectedCancelled', 'ReturnedCases', 'SR_Current', 'SR_Data', 'ST_EditorList', 'Ticketing', 'TransferToGeoData', 'Urgent', 'VIP',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ec8db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot mask with non-boolean array containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mdate()\n\u001b[0;32m     29\u001b[0m start \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m compCases \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_evaluation_sheet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_postgres\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 27\u001b[0m, in \u001b[0;36mgenerate_evaluation_sheet\u001b[1;34m(engine, start_date, end_date)\u001b[0m\n\u001b[0;32m     22\u001b[0m completed \u001b[38;5;241m=\u001b[39m join_userlist(completed, editorList)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# print(value)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# print(len(completed))\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# print(completed.head())\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompleted\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcompleted\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGeo Supervisor Recommendation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mيعاد\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Aaltoum\\.conda\\envs\\arcgis\\Lib\\site-packages\\pandas\\core\\frame.py:3751\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3748\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhere(key)\n\u001b[0;32m   3750\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m-> 3751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   3752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   3754\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3755\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Aaltoum\\.conda\\envs\\arcgis\\Lib\\site-packages\\pandas\\core\\common.py:134\u001b[0m, in \u001b[0;36mis_bool_indexer\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    130\u001b[0m     na_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot mask with non-boolean array containing NA / NaN values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39minfer_dtype(key_array) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m isna(key_array)\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;66;03m# Don't raise on e.g. [\"A\", \"B\", np.nan], see\u001b[39;00m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;66;03m#  test_loc_getitem_list_of_labels_categoricalindex_with_na\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(na_msg)\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot mask with non-boolean array containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "query_sql = \"\"\"SELECT * FROM grsdbrd.\"{}\" \"\"\"\n",
    "query_post = \"\"\"SELECT * FROM public.\"{}\" \"\"\"\n",
    "\n",
    "def join_userlist(comp_df, editorlist):\n",
    "    comp_df['GEO S Completion'] = pd.to_datetime(comp_df['GEO S Completion']).dt.normalize()\n",
    "    editorlist = editorlist.rename({'CaseProtalName': 'Geo Supervisor'},axis=1)\n",
    "    editorlist[\"ListDate\"] = pd.to_datetime(editorlist[\"ListDate\"]).dt.normalize()\n",
    "    comp_df = comp_df.sort_values(by=[\"GEO S Completion\", \"Geo Supervisor\"])\n",
    "    editorlist = editorlist.sort_values(by=[\"ListDate\", \"Geo Supervisor\"])\n",
    "    comp_df = pd.merge_asof(comp_df, editorlist, by=\"Geo Supervisor\", left_on=\"GEO S Completion\", \n",
    "                            right_on=\"ListDate\", direction='backward')\n",
    "    comp_df['GEO S Completion'] = [pd.to_datetime(i).date() for i in comp_df['GEO S Completion']]\n",
    "    comp_df['ListDate'] = [pd.to_datetime(i).date() for i in comp_df['ListDate']]\n",
    "    return comp_df\n",
    "\n",
    "\n",
    "def generate_evaluation_sheet(engine, start_date, end_date):\n",
    "    query = query_post+ \"\"\"WHERE \"GEO S Completion\" BETWEEN '{}' AND '{}' \"\"\"\n",
    "    value = query.format(tables[7], str(start_date), str(end_date))\n",
    "    completed = convert_to_date(pd.read_sql(value, engine))\n",
    "    editorList = convert_to_date(pd.read_sql(query_post.format(tables[5]), engine_postgres))\n",
    "    completed = join_userlist(completed, editorList)\n",
    "    completed = completed.dropna('Geo Supervisor Recommendation')\n",
    "    return completed[completed['Geo Supervisor Recommendation'].str.contains('يعاد')]\n",
    "end = datetime.now().date()\n",
    "start = end - timedelta(days=7)\n",
    "compCases = generate_evaluation_sheet(engine_postgres,start, end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28ba4787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Absolute Ownership', 'Duplicate Case',\n",
       "       'Generated Titles', 'Case Submission Date', 'Latest Action Date',\n",
       "       'Action', 'Assignee', 'Transferred to Geospatial', 'Return To Geo Team',\n",
       "       'Count of Returns Cases ', 'GEO Completion', 'GEO S Completion',\n",
       "       'Transferred to Ops', 'Case Status', 'REN', 'Boundary Length Deed',\n",
       "       'Boundary Length Parcel', 'MoJ Deed Number', 'Moj Real Estate Serial',\n",
       "       'MoJ Plan #', 'MoJ Real Estate Area', 'MoJ Land Number', 'City Name',\n",
       "       'District Name', 'MoJ Deed Area Text', 'Property Type',\n",
       "       'Parcel Area Size', 'Parcel Number (PCP)', 'Location Description',\n",
       "       'Attachments', 'Attachment Added Date', 'Deed East Limit Description',\n",
       "       'Deed East Limit Length', 'Deed Eastern Type',\n",
       "       'Deed  West Limit Description', 'Deed West Limit Length',\n",
       "       'Deed Western Boarder Type', 'Deed North Limit Description',\n",
       "       'Deed North Limit Length', 'Deed Northern Boarder Type',\n",
       "       'Deed South Limit Description', 'Deed South Limit Length',\n",
       "       'Deed Sothern Boarder Type', 'CW', 'CW Recommendation', 'CWS',\n",
       "       'CWS Recommendation', 'QC', 'QC Recommendation', 'GEO',\n",
       "       'GEO Recommendation', 'Geo Supervisor', 'Geo Supervisor Recommendation',\n",
       "       'UniqueKey', 'UploadDate', 'UploadedBy', 'EditorName', 'UserID',\n",
       "       'SupervisorID', 'SupervisorName', 'GroupID', 'ListDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compCases.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572f2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
